# Fine-Tuning-
Fine-tuning TinyLLaMA on a custom dataset for specialized text generation or Q&amp;A tasks, using 4-bit quantization to stay lightweight and efficient.
